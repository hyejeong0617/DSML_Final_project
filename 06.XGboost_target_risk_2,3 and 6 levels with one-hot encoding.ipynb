{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3351f34",
      "metadata": {},
      "source": [
        "##### Binary classification with simple one-hot encoding \n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f20ba05",
      "metadata": {
        "id": "1f20ba05"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(r\"F:\\Final_project\\rasff_new2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3faccd27",
      "metadata": {
        "id": "3faccd27",
        "outputId": "acb69e25-d3ae-4dcb-8f63-b4b4d910a43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27397 entries, 0 to 27396\n",
            "Data columns (total 18 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   reference              27397 non-null  float64\n",
            " 1   category               27397 non-null  object \n",
            " 2   type                   27397 non-null  object \n",
            " 3   subject                27397 non-null  object \n",
            " 4   date                   27397 non-null  object \n",
            " 5   notifying_country      27397 non-null  object \n",
            " 6   classification         27397 non-null  object \n",
            " 7   risk_decision          27397 non-null  object \n",
            " 8   distribution           18759 non-null  object \n",
            " 9   forAttention           14966 non-null  object \n",
            " 10  forFollowUp            13810 non-null  object \n",
            " 11  operator               27303 non-null  object \n",
            " 12  origin                 26823 non-null  object \n",
            " 13  hazards                20241 non-null  object \n",
            " 14  year                   27397 non-null  int64  \n",
            " 15  month                  27397 non-null  int64  \n",
            " 16  Hazard_Type            27397 non-null  object \n",
            " 17  Regulatory_Issue_Flag  27397 non-null  int64  \n",
            "dtypes: float64(1), int64(3), object(14)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "437e1c64",
      "metadata": {
        "id": "437e1c64",
        "outputId": "2528661e-a781-4ff8-e92e-3ef2342badda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "category\n",
              "fruits and vegetables                                   4934\n",
              "nuts, nut products and seeds                            3291\n",
              "poultry meat and poultry meat products                  2309\n",
              "dietetic foods, food supplements and fortified foods    1947\n",
              "cereals and bakery products                             1779\n",
              "herbs and spices                                        1763\n",
              "fish and fish products                                  1476\n",
              "meat and meat products (other than poultry)             1155\n",
              "food contact materials                                  1114\n",
              "feed materials                                          1072\n",
              "other food product / mixed                              1068\n",
              "milk and milk products                                   655\n",
              "prepared dishes and snacks                               633\n",
              "confectionery                                            633\n",
              "bivalve molluscs and products thereof                    541\n",
              "cocoa and cocoa preparations, coffee and tea             512\n",
              "crustaceans and products thereof                         401\n",
              "soups, broths, sauces and condiments                     328\n",
              "fats and oils                                            285\n",
              "non-alcoholic beverages                                  263\n",
              "pet food                                                 219\n",
              "food additives and flavourings                           187\n",
              "compound feeds                                           149\n",
              "cephalopods and products thereof                         128\n",
              "eggs and egg products                                    121\n",
              "ices and desserts                                        119\n",
              "alcoholic beverages                                       89\n",
              "feed additives                                            54\n",
              "honey and royal jelly                                     45\n",
              "natural mineral waters                                    25\n",
              "feed premixtures                                          23\n",
              "water for human consumption (other)                       23\n",
              "animal by-products                                        22\n",
              "wine                                                      15\n",
              "gastropods                                                12\n",
              "live animals                                               6\n",
              "plant protection products                                  1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1912a61",
      "metadata": {
        "id": "d1912a61",
        "outputId": "39be2452-e7d9-4b3a-f3a4-74f9b0ff6888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "risk_decision_2class\n",
            "1    14756\n",
            "0    12641\n",
            "Name: count, dtype: int64\n",
            "Handling NaNs in selected features: ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
            "Feature matrix (X) shape after encoding: (27397, 27418)\n",
            "X now contains 27418 features (One-Hot Encoded variables).\n",
            "\n",
            "Training Logistic Regression baseline model...\n",
            "\n",
            "--- BASELINE MODEL RESULTS ---\n",
            "Baseline Model Accuracy: 0.8549\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      3793\n",
            "           1       0.85      0.89      0.87      4427\n",
            "\n",
            "    accuracy                           0.85      8220\n",
            "   macro avg       0.86      0.85      0.85      8220\n",
            "weighted avg       0.86      0.85      0.85      8220\n",
            "\n",
            "Majority Class Baseline Accuracy (if model always guessed the majority class): 0.5386\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Recode risk_decision into 2 classes\n",
        "# ----------------------------\n",
        "def recode_risk(risk):\n",
        "    if risk in ['no risk', 'not serious', 'potential risk', 'undecided', 'potentially serious']:\n",
        "        return 0   # Lower to medium risk\n",
        "    elif risk == 'serious':\n",
        "        return 1   # High risk\n",
        "    else:\n",
        "        return -1  # Safety net for unexpected values\n",
        "\n",
        "df['risk_decision_2class']=df['risk_decision'].apply(recode_risk)\n",
        "print(df['risk_decision_2class'].value_counts())\n",
        "\n",
        "# Define the original target column name\n",
        "TARGET = 'risk_decision_2class'\n",
        "df.dropna(subset=[TARGET], inplace=True) # Ensure target is not null\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. Feature Selection and Engineering (Revised) ---\n",
        "# Use ONLY the five specified categorical features\n",
        "FEATURES = ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
        "\n",
        "# Create a filtered DataFrame containing only the features and the binary target\n",
        "df_model = df[FEATURES + ['risk_decision_2class']].copy()\n",
        "\n",
        "# Handle missing values by filling with a simple placeholder 'missing'\n",
        "print(f\"Handling NaNs in selected features: {FEATURES}\")\n",
        "df_model[FEATURES] = df_model[FEATURES].fillna('missing')\n",
        "\n",
        "# One-Hot Encoding for all selected categorical features\n",
        "df_encoded = pd.get_dummies(df_model, columns=FEATURES, drop_first=True)\n",
        "\n",
        "# Define X (features: all OHE columns) and y (target)\n",
        "X = df_encoded.drop(columns=['risk_decision_2class'])\n",
        "y = df_encoded['risk_decision_2class']\n",
        "\n",
        "print(f\"Feature matrix (X) shape after encoding: {X.shape}\")\n",
        "print(f\"X now contains {len(X.columns)} features (One-Hot Encoded variables).\")\n",
        "\n",
        "\n",
        "# --- 4. Split Data ---\n",
        "# Stratify ensures the train/test split maintains the same proportion of the target class\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# --- 5. Model Training (Logistic Regression Baseline) ---\n",
        "# Use 'liblinear' solver for smaller datasets or when using L1/L2 regularization\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "print(\"\\nTraining Logistic Regression baseline model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Evaluation ---\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- BASELINE MODEL RESULTS ---\")\n",
        "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note about the majority class:\n",
        "majority_accuracy = y.value_counts(normalize=True).max()\n",
        "print(f\"Majority Class Baseline Accuracy (if model always guessed the majority class): {majority_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fiu5RnnQr5Uo",
      "metadata": {
        "id": "fiu5RnnQr5Uo"
      },
      "source": [
        "3 level risk decision with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f618d63",
      "metadata": {
        "id": "9f618d63"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(r\"/content/df_keyword.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T6gmgRZAsG3K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6gmgRZAsG3K",
        "outputId": "d9b8b7f8-5838-4c94-96a6-fe54111efe67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27397 entries, 0 to 27396\n",
            "Data columns (total 23 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   reference                  27397 non-null  float64\n",
            " 1   category                   27397 non-null  object \n",
            " 2   type                       27397 non-null  object \n",
            " 3   subject                    27397 non-null  object \n",
            " 4   date                       27397 non-null  object \n",
            " 5   notifying_country          27397 non-null  object \n",
            " 6   classification             27397 non-null  object \n",
            " 7   risk_decision              27397 non-null  object \n",
            " 8   distribution               18759 non-null  object \n",
            " 9   forAttention               14966 non-null  object \n",
            " 10  forFollowUp                13810 non-null  object \n",
            " 11  operator                   27303 non-null  object \n",
            " 12  origin                     26823 non-null  object \n",
            " 13  hazards                    20241 non-null  object \n",
            " 14  year                       27397 non-null  int64  \n",
            " 15  month                      27397 non-null  int64  \n",
            " 16  Hazard_Type                27397 non-null  object \n",
            " 17  Regulatory_Issue_Flag      27397 non-null  int64  \n",
            " 18  hazard_cleaned             20241 non-null  object \n",
            " 19  hazard_text                20241 non-null  object \n",
            " 20  detected_keywords          27397 non-null  object \n",
            " 21  simplified_hazard          20241 non-null  object \n",
            " 22  extracted_hazard_keywords  27397 non-null  object \n",
            "dtypes: float64(1), int64(3), object(19)\n",
            "memory usage: 4.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2CgdVGEEsF_c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CgdVGEEsF_c",
        "outputId": "86d61144-f109-4d2c-bcee-6374717c31a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "risk_decision_3class\n",
            "2    14756\n",
            "1     8090\n",
            "0     4551\n",
            "Name: count, dtype: int64\n",
            "Handling NaNs in selected features: ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
            "Feature matrix (X) shape after encoding: (27397, 27418)\n",
            "X now contains 27418 features (One-Hot Encoded variables).\n",
            "\n",
            "Training Logistic Regression baseline model...\n",
            "\n",
            "--- BASELINE MODEL RESULTS ---\n",
            "Baseline Model Accuracy: 0.7563\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.54      0.60      1366\n",
            "           1       0.66      0.59      0.62      2427\n",
            "           2       0.82      0.92      0.86      4427\n",
            "\n",
            "    accuracy                           0.76      8220\n",
            "   macro avg       0.72      0.68      0.69      8220\n",
            "weighted avg       0.75      0.76      0.75      8220\n",
            "\n",
            "Majority Class Baseline Accuracy (if model always guessed the majority class): 0.5386\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Recode risk_decision into 3 classes\n",
        "# ----------------------------\n",
        "def recode_risk(risk):\n",
        "    if risk in ['no risk', 'not serious']:\n",
        "        return 0   # Low risk\n",
        "    elif risk in ['potential risk', 'undecided', 'potentially serious']:\n",
        "        return 1   # Medium / potential risk\n",
        "    elif risk == 'serious':\n",
        "        return 2   # High risk\n",
        "    else:\n",
        "        return -1  # Safety net for unexpected values\n",
        "\n",
        "\n",
        "df['risk_decision_3class']=df['risk_decision'].apply(recode_risk)\n",
        "print(df['risk_decision_3class'].value_counts())\n",
        "\n",
        "# Define the original target column name\n",
        "TARGET = 'risk_decision_3class'\n",
        "df.dropna(subset=[TARGET], inplace=True) # Ensure target is not null\n",
        "\n",
        "\n",
        "# --- 3. Feature Selection and Engineering (Revised) ---\n",
        "# Use ONLY the five specified categorical features\n",
        "FEATURES = ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
        "\n",
        "# Create a filtered DataFrame containing only the features and the binary target\n",
        "df_model = df[FEATURES + ['risk_decision_3class']].copy()\n",
        "\n",
        "# Handle missing values by filling with a simple placeholder 'missing'\n",
        "print(f\"Handling NaNs in selected features: {FEATURES}\")\n",
        "df_model[FEATURES] = df_model[FEATURES].fillna('missing')\n",
        "\n",
        "# One-Hot Encoding for all selected categorical features\n",
        "df_encoded = pd.get_dummies(df_model, columns=FEATURES, drop_first=True)\n",
        "\n",
        "# Define X (features: all OHE columns) and y (target)\n",
        "X = df_encoded.drop(columns=['risk_decision_3class'])\n",
        "y = df_encoded['risk_decision_3class']\n",
        "\n",
        "print(f\"Feature matrix (X) shape after encoding: {X.shape}\")\n",
        "print(f\"X now contains {len(X.columns)} features (One-Hot Encoded variables).\")\n",
        "\n",
        "\n",
        "# --- 4. Split Data ---\n",
        "# Stratify ensures the train/test split maintains the same proportion of the target class\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# --- 5. Model Training (Logistic Regression Baseline) ---\n",
        "# Use 'liblinear' solver for smaller datasets or when using L1/L2 regularization\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "print(\"\\nTraining Logistic Regression baseline model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Evaluation ---\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- BASELINE MODEL RESULTS ---\")\n",
        "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note about the majority class:\n",
        "majority_accuracy = y.value_counts(normalize=True).max()\n",
        "print(f\"Majority Class Baseline Accuracy (if model always guessed the majority class): {majority_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ouQBIB3hsx5K",
      "metadata": {
        "id": "ouQBIB3hsx5K"
      },
      "source": [
        "6 risk level with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q_lJZLpIswhL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_lJZLpIswhL",
        "outputId": "c5d9db92-5e7a-4e4d-f25f-9d0c0bfe0d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "risk_decision\n",
            "serious                14756\n",
            "not serious             4134\n",
            "undecided               3029\n",
            "potential risk          2689\n",
            "potentially serious     2372\n",
            "no risk                  417\n",
            "Name: count, dtype: int64\n",
            "Handling NaNs in selected features: ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
            "Feature matrix (X) shape after encoding: (27397, 27418)\n",
            "X now contains 27418 features (One-Hot Encoded variables).\n",
            "\n",
            "Training Logistic Regression baseline model...\n",
            "\n",
            "--- BASELINE MODEL RESULTS ---\n",
            "Baseline Model Accuracy: 0.6899\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            no risk       0.48      0.08      0.14       125\n",
            "        not serious       0.55      0.72      0.62      1240\n",
            "     potential risk       0.42      0.29      0.35       807\n",
            "potentially serious       0.45      0.12      0.19       712\n",
            "            serious       0.78      0.95      0.86      4427\n",
            "          undecided       0.50      0.26      0.34       909\n",
            "\n",
            "           accuracy                           0.69      8220\n",
            "          macro avg       0.53      0.40      0.42      8220\n",
            "       weighted avg       0.65      0.69      0.65      8220\n",
            "\n",
            "Majority Class Baseline Accuracy (if model always guessed the majority class): 0.5386\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the original target column name\n",
        "print(df['risk_decision'].value_counts())\n",
        "\n",
        "TARGET = 'risk_decision'\n",
        "df.dropna(subset=[TARGET], inplace=True) # Ensure target is not null\n",
        "\n",
        "\n",
        "# --- 3. Feature Selection and Engineering (Revised) ---\n",
        "# Use ONLY the five specified categorical features\n",
        "FEATURES = ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
        "\n",
        "# Create a filtered DataFrame containing only the features and the binary target\n",
        "df_model = df[FEATURES + ['risk_decision']].copy()\n",
        "\n",
        "# Handle missing values by filling with a simple placeholder 'missing'\n",
        "print(f\"Handling NaNs in selected features: {FEATURES}\")\n",
        "df_model[FEATURES] = df_model[FEATURES].fillna('missing')\n",
        "\n",
        "# One-Hot Encoding for all selected categorical features\n",
        "df_encoded = pd.get_dummies(df_model, columns=FEATURES, drop_first=True)\n",
        "\n",
        "# Define X (features: all OHE columns) and y (target)\n",
        "X = df_encoded.drop(columns=['risk_decision'])\n",
        "y = df_encoded['risk_decision']\n",
        "\n",
        "print(f\"Feature matrix (X) shape after encoding: {X.shape}\")\n",
        "print(f\"X now contains {len(X.columns)} features (One-Hot Encoded variables).\")\n",
        "\n",
        "\n",
        "# --- 4. Split Data ---\n",
        "# Stratify ensures the train/test split maintains the same proportion of the target class\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# --- 5. Model Training (Logistic Regression Baseline) ---\n",
        "# Use 'liblinear' solver for smaller datasets or when using L1/L2 regularization\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "print(\"\\nTraining Logistic Regression baseline model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Evaluation ---\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- BASELINE MODEL RESULTS ---\")\n",
        "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note about the majority class:\n",
        "majority_accuracy = y.value_counts(normalize=True).max()\n",
        "print(f\"Majority Class Baseline Accuracy (if model always guessed the majority class): {majority_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t4dF9puOtxl2",
      "metadata": {
        "id": "t4dF9puOtxl2"
      },
      "source": [
        "3 level with one-hot encoding XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BKjcV2DEtmK3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKjcV2DEtmK3",
        "outputId": "cc30514a-319a-4c13-8fe0-870a2eb0d2f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "risk_decision_3class\n",
            "2    14756\n",
            "1     8090\n",
            "0     4551\n",
            "Name: count, dtype: int64\n",
            "Handling NaNs in selected features: ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
            "Feature matrix (X) shape after encoding: (27397, 27418)\n",
            "X now contains 27418 features (One-Hot Encoded variables).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pandas/core/strings/object_array.py:172: FutureWarning: Possible nested set at position 1\n",
            "  pat = re.compile(pat, flags=flags)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBoost baseline model...\n",
            "\n",
            "--- BASELINE MODEL RESULTS ---\n",
            "Baseline Model Accuracy: 0.7557\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.59      0.62       910\n",
            "           1       0.70      0.51      0.59      1618\n",
            "           2       0.80      0.94      0.87      2952\n",
            "\n",
            "    accuracy                           0.76      5480\n",
            "   macro avg       0.72      0.68      0.69      5480\n",
            "weighted avg       0.75      0.76      0.74      5480\n",
            "\n",
            "Majority Class Baseline Accuracy (if model always guessed the majority class): 0.5386\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Recode risk_decision into 3 classes\n",
        "# ----------------------------\n",
        "def recode_risk(risk):\n",
        "    if risk in ['no risk', 'not serious']:\n",
        "        return 0   # Low risk\n",
        "    elif risk in ['potential risk', 'undecided', 'potentially serious']:\n",
        "        return 1   # Medium / potential risk\n",
        "    elif risk == 'serious':\n",
        "        return 2   # High risk\n",
        "    else:\n",
        "        return -1  # Safety net for unexpected values\n",
        "\n",
        "\n",
        "df['risk_decision_3class']=df['risk_decision'].apply(recode_risk)\n",
        "print(df['risk_decision_3class'].value_counts())\n",
        "\n",
        "# Define the original target column name\n",
        "TARGET = 'risk_decision_3class'\n",
        "df.dropna(subset=[TARGET], inplace=True) # Ensure target is not null\n",
        "\n",
        "\n",
        "# --- 3. Feature Selection and Engineering (Revised) ---\n",
        "# Use ONLY the five specified categorical features\n",
        "FEATURES = ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
        "\n",
        "# Create a filtered DataFrame containing only the features and the binary target\n",
        "df_model = df[FEATURES + ['risk_decision_3class']].copy()\n",
        "\n",
        "# Handle missing values by filling with a simple placeholder 'missing'\n",
        "print(f\"Handling NaNs in selected features: {FEATURES}\")\n",
        "df_model[FEATURES] = df_model[FEATURES].fillna('missing')\n",
        "\n",
        "# One-Hot Encoding for all selected categorical features\n",
        "df_encoded = pd.get_dummies(df_model, columns=FEATURES, drop_first=True)\n",
        "\n",
        "# Define X (features: all OHE columns) and y (target)\n",
        "X = df_encoded.drop(columns=['risk_decision_3class'])\n",
        "y = df_encoded['risk_decision_3class']\n",
        "\n",
        "print(f\"Feature matrix (X) shape after encoding: {X.shape}\")\n",
        "print(f\"X now contains {len(X.columns)} features (One-Hot Encoded variables).\")\n",
        "\n",
        "# =====================================================\n",
        "# Sanitize feature names for  compatibility\n",
        "# =====================================================\n",
        "\n",
        "# LightGBM/XGBoost does not allow characters: {}[]:\"', etc.\n",
        "X.columns = (\n",
        "    X.columns\n",
        "      .str.replace(r'[[\\]{}\\\":\\\"\\',]', '_', regex=True)\n",
        "      .str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)   # extra safety\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Split Data ---\n",
        "# Stratify ensures the train/test split maintains the same proportion of the target class\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y)\n",
        "\n",
        "# =====================================================\n",
        "# 8. XGBoost Model\n",
        "# =====================================================\n",
        "model = XGBClassifier(\n",
        "    eval_metric=\"logloss\",\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"\\nTraining XGBoost baseline model...\")\n",
        "model.fit(X_train.values, y_train)\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Evaluation ---\n",
        "y_pred = model.predict(X_test.values)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- BASELINE MODEL RESULTS ---\")\n",
        "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note about the majority class:\n",
        "majority_accuracy = y.value_counts(normalize=True).max()\n",
        "print(f\"Majority Class Baseline Accuracy (if model always guessed the majority class): {majority_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xOQiS3djxNZU",
      "metadata": {
        "id": "xOQiS3djxNZU"
      },
      "source": [
        "2 level one hot encoding with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AbVV690PxQp4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbVV690PxQp4",
        "outputId": "5656b6c4-2cf9-4604-fb83-832cf3e2b085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "risk_decision_2class\n",
            "1    14756\n",
            "0    12641\n",
            "Name: count, dtype: int64\n",
            "Handling NaNs in selected features: ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
            "Feature matrix (X) shape after encoding: (27397, 27418)\n",
            "X now contains 27418 features (One-Hot Encoded variables).\n",
            "\n",
            "Training XGBoost baseline model...\n",
            "\n",
            "--- BASELINE MODEL RESULTS ---\n",
            "Baseline Model Accuracy: 0.8540\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.84      2528\n",
            "           1       0.85      0.89      0.87      2952\n",
            "\n",
            "    accuracy                           0.85      5480\n",
            "   macro avg       0.86      0.85      0.85      5480\n",
            "weighted avg       0.85      0.85      0.85      5480\n",
            "\n",
            "Majority Class Baseline Accuracy (if model always guessed the majority class): 0.5386\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Recode risk_decision into 2 classes\n",
        "# ----------------------------\n",
        "def recode_risk(risk):\n",
        "    if risk in ['no risk', 'not serious', 'potential risk', 'undecided', 'potentially serious']:\n",
        "        return 0   # Lower to medium risk\n",
        "    elif risk == 'serious':\n",
        "        return 1   # High risk\n",
        "    else:\n",
        "        return -1  # Safety net for unexpected values\n",
        "\n",
        "df['risk_decision_2class']=df['risk_decision'].apply(recode_risk)\n",
        "print(df['risk_decision_2class'].value_counts())\n",
        "\n",
        "# Define the original target column name\n",
        "TARGET = 'risk_decision_2class'\n",
        "df.dropna(subset=[TARGET], inplace=True) # Ensure target is not null\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. Feature Selection and Engineering (Revised) ---\n",
        "# Use ONLY the five specified categorical features\n",
        "FEATURES = ['category', 'type', 'subject', 'origin', 'classification', 'hazards']\n",
        "\n",
        "# Create a filtered DataFrame containing only the features and the binary target\n",
        "df_model = df[FEATURES + ['risk_decision_2class']].copy()\n",
        "\n",
        "# Handle missing values by filling with a simple placeholder 'missing'\n",
        "print(f\"Handling NaNs in selected features: {FEATURES}\")\n",
        "df_model[FEATURES] = df_model[FEATURES].fillna('missing')\n",
        "\n",
        "# One-Hot Encoding for all selected categorical features\n",
        "df_encoded = pd.get_dummies(df_model, columns=FEATURES, drop_first=True)\n",
        "\n",
        "# Define X (features: all OHE columns) and y (target)\n",
        "X = df_encoded.drop(columns=['risk_decision_2class'])\n",
        "y = df_encoded['risk_decision_2class']\n",
        "\n",
        "print(f\"Feature matrix (X) shape after encoding: {X.shape}\")\n",
        "print(f\"X now contains {len(X.columns)} features (One-Hot Encoded variables).\")\n",
        "\n",
        "# =====================================================\n",
        "# Sanitize feature names for  compatibility\n",
        "# =====================================================\n",
        "\n",
        "# LightGBM/XGBoost does not allow characters: {}[]:\"', etc.\n",
        "X.columns = (\n",
        "    X.columns\n",
        "      .str.replace(r'[[\\]{}\\\":\\\"\\',]', '_', regex=True)\n",
        "      .str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)   # extra safety\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Split Data ---\n",
        "# Stratify ensures the train/test split maintains the same proportion of the target class\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y)\n",
        "\n",
        "# =====================================================\n",
        "# 8. XGBoost Model\n",
        "# =====================================================\n",
        "model = XGBClassifier(\n",
        "    eval_metric=\"logloss\",\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"\\nTraining XGBoost baseline model...\")\n",
        "model.fit(X_train.values, y_train)\n",
        "\n",
        "\n",
        "# --- 6. Prediction and Evaluation ---\n",
        "y_pred = model.predict(X_test.values)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- BASELINE MODEL RESULTS ---\")\n",
        "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note about the majority class:\n",
        "majority_accuracy = y.value_counts(normalize=True).max()\n",
        "print(f\"Majority Class Baseline Accuracy (if model always guessed the majority class): {majority_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
